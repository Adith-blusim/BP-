{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "11wuEZozrtzo5cTOYrew6sA770Awr38KH",
      "authorship_tag": "ABX9TyN4WHFeNWEpmuwOsHsEUD/X",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Adith-blusim/BP-/blob/main/interpolation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2EuIQn-bxjL2"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "# Original list with 61 data points\n",
        "original_data = [0, -16, -16, 32, 16, -16, 32, 32, 32, 0, 32, -16, -16, 32, 0, -16, 0, 32, 32, 0, -16, 32, 32, -16, 16, 32, -16, -16, 32, -16, -16, 32, 16, -16, -16, 32, -16, -16, 16, -16, 32, 32, -16, 32, -16, -16, 32, 0, -16, 32, 32, -16, 32, 32, -16, 0, -16, 32, -16, -16, 32, -16, -16, 32, 16, -16, 16, 32, -16, -16, 32, 32]\n",
        "# Number of data points after expansion\n",
        "desired_data_points = 200\n",
        "# Generate indices for the expanded data\n",
        "expanded_indices = np.linspace(0, len(original_data) - 1, desired_data_points)  # Return evenly spaced numbers over a specified interval\n",
        "# Perform linear interpolation\n",
        "expanded_data = np.interp(expanded_indices, np.arange(len(original_data)), original_data)\n",
        "# Plot both the original and expanded data\n",
        "plt.figure(figsize=(20, 5))\n",
        "plt.plot(np.arange(len(original_data)), original_data, 'o-', label='Original Data', color='blue')\n",
        "plt.plot(expanded_indices, expanded_data, 'o--', label='Expanded Data', color='orange')\n",
        "plt.title('Original and Expanded Data')\n",
        "plt.xlabel('Index')\n",
        "plt.ylabel('Value')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gtXMSr0o1954"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.interpolate import CubicSpline\n",
        "\n",
        "# Original list with 61 data points\n",
        "original_data = [0, -16, -16, 32, 16, -16, 32, 32, 32, 0, 32, -16, -16, 32, 0, -16, 0, 32, 32, 0, -16, 32, 32, -16, 16, 32, -16, -16, 32, -16, -16, 32, 16, -16, -16, 32, -16, -16, 16, -16, 32, 32, -16, 32, -16, -16, 32, 0, -16, 32, 32, -16, 32, 32, -16, 0, -16, 32, -16, -16, 32, -16, -16, 32, 16, -16, 16, 32, -16, -16, 32, 32]\n",
        "\n",
        "# Number of data points after expansion\n",
        "desired_data_points = 200\n",
        "\n",
        "# Generate indices for the expanded data\n",
        "expanded_indices = np.linspace(0, len(original_data) - 1, desired_data_points)\n",
        "\n",
        "# Perform cubic spline interpolation\n",
        "cs = CubicSpline(np.arange(len(original_data)), original_data, bc_type='clamped')\n",
        "expanded_data_cubic = cs(expanded_indices)\n",
        "\n",
        "# Plot both the original and expanded data using linear and cubic spline interpolation\n",
        "plt.figure(figsize=(20, 5))\n",
        "plt.plot(np.arange(len(original_data)), original_data, 'o-', label='Original Data', color='blue')\n",
        "plt.plot(expanded_indices, expanded_data, 'o--', label='Linear Interpolation', color='orange')\n",
        "plt.plot(expanded_indices, expanded_data_cubic, 'x-', label='Cubic Spline Interpolation', color='green')\n",
        "plt.title('Original and Interpolated Data')\n",
        "plt.xlabel('Index')\n",
        "plt.ylabel('Value')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.interpolate import Akima1DInterpolator\n",
        "\n",
        "# Original list with 61 data points\n",
        "original_data = [0, -16, -16, 32, 16, -16, 32, 32, 32, 0, 32, -16, -16, 32, 0, -16, 0, 32, 32, 0, -16, 32, 32, -16, 16, 32, -16, -16, 32, -16, -16, 32, 16, -16, -16, 32, -16, -16, 16, -16, 32, 32, -16, 32, -16, -16, 32, 0, -16, 32, 32, -16, 32, 32, -16, 0, -16, 32, -16, -16, 32, -16, -16, 32, 16, -16, 16, 32, -16, -16, 32, 32]\n",
        "\n",
        "# Number of data points after expansion\n",
        "desired_data_points = 200\n",
        "\n",
        "# Generate indices for the expanded data\n",
        "expanded_indices = np.linspace(0, len(original_data) - 1, desired_data_points)\n",
        "\n",
        "# Perform Akima 1D interpolation\n",
        "akima_interpolator = Akima1DInterpolator(np.arange(len(original_data)), original_data)\n",
        "expanded_data_akima = akima_interpolator(expanded_indices)\n",
        "\n",
        "# Plot both the original and expanded data using linear and Akima 1D interpolation\n",
        "plt.figure(figsize=(20, 5))\n",
        "plt.plot(np.arange(len(original_data)), original_data, 'o-', label='Original Data', color='blue')\n",
        "plt.plot(expanded_indices, expanded_data, 'o--', label='Linear Interpolation', color='orange')\n",
        "plt.plot(expanded_indices, expanded_data_akima, '^-', label='Akima 1D Interpolation', color='maroon')\n",
        "plt.title('Original and Interpolated Data')\n",
        "plt.xlabel('Index')\n",
        "plt.ylabel('Value')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "I3TytyZIPIu9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.interpolate import pchip\n",
        "\n",
        "# Original list with 61 data points\n",
        "original_data = [0, -16, -16, 32, 16, -16, 32, 32, 32, 0, 32, -16, -16, 32, 0, -16, 0, 32, 32, 0, -16, 32, 32, -16, 16, 32, -16, -16, 32, -16, -16, 32, 16, -16, -16, 32, -16, -16, 16, -16, 32, 32, -16, 32, -16, -16, 32, 0, -16, 32, 32, -16, 32, 32, -16, 0, -16, 32, -16, -16, 32, -16, -16, 32, 16, -16, 16, 32, -16, -16, 32, 32]\n",
        "\n",
        "# Number of data points after expansion\n",
        "desired_data_points = 200\n",
        "\n",
        "# Generate indices for the expanded data\n",
        "expanded_indices = np.linspace(0, len(original_data) - 1, desired_data_points)\n",
        "\n",
        "# Perform PCHIP interpolation\n",
        "pchip_interpolator = pchip(np.arange(len(original_data)), original_data)\n",
        "expanded_data_pchip = pchip_interpolator(expanded_indices)\n",
        "\n",
        "# Plot both the original and expanded data using linear and PCHIP interpolation\n",
        "plt.figure(figsize=(20, 5))\n",
        "plt.plot(np.arange(len(original_data)), original_data, 'o-', label='Original Data', color='blue')\n",
        "plt.plot(expanded_indices, expanded_data, 'o--', label='Linear Interpolation', color='orange')\n",
        "plt.plot(expanded_indices, expanded_data_pchip, 's-', label='PCHIP Interpolation', color='violet')\n",
        "plt.title('Original and Interpolated Data')\n",
        "plt.xlabel('Index')\n",
        "plt.ylabel('Value')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "y3mWNGF1NCJW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Deleting all values of \"sys\" greater than 121:\n",
        "#seconds data\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "df = pd.read_csv(\"/content/drive/MyDrive/blusim/roi_updated_data.csv\")\n",
        "df = df.dropna()\n",
        "df = df.reset_index(drop=True)\n",
        "df = df.drop(['Unix Timestamp','RESP','ECG','SPO2','PR'],axis=1)\n",
        "\n",
        "def extract_nibp_values(value):\n",
        "    # Remove spaces and extra brackets, extract the digits\n",
        "    cleaned_value = ''.join(filter(str.isdigit, value.replace(' ', '').replace('(', '').replace(')', '')))\n",
        "    sys_value = cleaned_value[:3]\n",
        "    dias_value = cleaned_value[3:5]\n",
        "    return sys_value, dias_value\n",
        "\n",
        "# Apply the function to \"NIBP\" column and create new columns \"sys\" and \"dias\"\n",
        "df['sys'], df['dias'] = zip(*df['NIBP'].apply(extract_nibp_values))\n",
        "\n",
        "rdf = pd.read_csv(\"/content/drive/MyDrive/blusim/mat_15.csv\")\n",
        "rdf['Timestamp'] = pd.to_datetime(rdf['Timestamp'], format='%H:%M:%S')\n",
        "df['Timestamp'] = pd.to_datetime(df['Timestamp'], format='%H:%M:%S')\n",
        "rdf['Timestamp'] = rdf['Timestamp'].dt.strftime('%H:%M:%S')\n",
        "\n",
        "df.set_index('Timestamp', inplace=True)\n",
        "rdf = rdf.groupby('Timestamp').agg(lambda x: x.tolist()).reset_index()\n",
        "rdf.set_index('Timestamp', inplace=True)\n",
        "df=df.resample('S').ffill()\n",
        "df.index = df.index.strftime('%H:%M:%S')\n",
        "\n",
        "ldf = pd.merge(rdf,df, left_index=True, right_index=True)\n",
        "ldf[['sys', 'dias']] = ldf[['sys', 'dias']].replace('', np.nan)\n",
        "ldf.dropna(how='any', inplace=True)\n",
        "ldf['sys'] = pd.to_numeric(ldf['sys'], errors='coerce')\n",
        "ldf['dias'] = pd.to_numeric(ldf['dias'], errors='coerce')\n",
        "ldf = ldf.drop(ldf[ldf['sys'].gt(140)].index)\n",
        "ldf = ldf.drop(ldf[ldf['dias'].gt(100)].index)\n",
        "ldf"
      ],
      "metadata": {
        "id": "F5hmabuBac47"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Linear"
      ],
      "metadata": {
        "id": "bw1Q3xASK1ga"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def interpolate_to_120(arr):\n",
        "\n",
        "    x_interp = np.linspace(0, len(arr) - 1, 120)\n",
        "    y_interp = np.interp(x_interp, np.arange(len(arr)), arr)\n",
        "    return y_interp.tolist()\n",
        "df_interpolated = ldf[['Raw_Value_ch1','Raw_Value_ch2','Raw_Value_ch3','Raw_Value_ch4']].applymap(interpolate_to_120)\n",
        "df_interpolated"
      ],
      "metadata": {
        "id": "MgME4TJVi-J9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cubic Spline"
      ],
      "metadata": {
        "id": "r3NOn4M0jTss"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.interpolate import CubicSpline\n",
        "def interpolate_to_120(arr):\n",
        "\n",
        "    cs_interpolator = CubicSpline(np.arange(len(arr)), arr, bc_type='clamped')\n",
        "    x_interp = np.linspace(0, len(arr) - 1, 120)\n",
        "    y_interp = cs_interpolator(x_interp)\n",
        "    return y_interp.tolist()\n",
        "df_interpolated = ldf[['Raw_Value_ch1','Raw_Value_ch2','Raw_Value_ch3','Raw_Value_ch4']].applymap(interpolate_to_120)\n",
        "df_interpolated"
      ],
      "metadata": {
        "id": "hVbnUFDIiN3b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "PCHIP"
      ],
      "metadata": {
        "id": "i_wggMcXjWRp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.interpolate import PchipInterpolator\n",
        "\n",
        "def interpolate_to_120(arr):\n",
        "\n",
        "    pchip_interpolator = PchipInterpolator(np.arange(len(arr)), arr)\n",
        "    x_interp = np.linspace(0, len(arr) - 1, 88)\n",
        "    y_interp = pchip_interpolator(x_interp)\n",
        "    return y_interp.tolist()\n",
        "\n",
        "df_interpolated = ldf[['Raw_Value_ch1','Raw_Value_ch2','Raw_Value_ch3','Raw_Value_ch4']].applymap(interpolate_to_120)\n",
        "df_interpolated"
      ],
      "metadata": {
        "id": "YfDBD01bgBOh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "minlen = (min(len(x) for x in df_interpolated['Raw_Value_ch1']))\n",
        "maxlen = (max(len(x) for x in df_interpolated['Raw_Value_ch1']))\n",
        "minlen,maxlen"
      ],
      "metadata": {
        "id": "ozFF_qhIK-8f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Signal Processing Part**"
      ],
      "metadata": {
        "id": "sWbyystiV0w8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Butterworth"
      ],
      "metadata": {
        "id": "eTEqGOOsYhqw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install EMD-signal\n",
        "from PyEMD import EMD\n",
        "from PyEMD import EEMD\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.signal import butter, lfilter\n",
        "\n",
        "# Sample rate and desired cutoff frequencies (in Hz)\n",
        "fs = 138.0\n",
        "lowcut = 0.5\n",
        "highcut = 6.0\n",
        "\n",
        "def butter_bandpass(lowcut, highcut, fs, order=3):\n",
        "    nyq = 0.5 * fs\n",
        "    low = lowcut / nyq\n",
        "    high = highcut / nyq\n",
        "    b, a = butter(order, [low, high], btype='band')\n",
        "    return b, a\n",
        "\n",
        "def butter_bandpass_filter(data, lowcut, highcut, fs, order=3):\n",
        "    b, a = butter_bandpass(lowcut, highcut, fs, order=order)\n",
        "    y = lfilter(b, a, data)\n",
        "    return y\n",
        "\n",
        "# Channel_1 = ldf['Raw_Value_ch1']\n",
        "# Channel_2 = ldf['Raw_Value_ch2']\n",
        "# Channel_3 = ldf['Raw_Value_ch3']\n",
        "# Channel_4 = ldf['Raw_Value_ch4']\n",
        "\n",
        "# Apply the Butterworth band-pass filter to the data\n",
        "bdf = pd.DataFrame()\n",
        "bdf['buttered_channel1'] = [butter_bandpass_filter(data, lowcut, highcut, fs, order=3) for data in df_interpolated['Raw_Value_ch1']]\n",
        "bdf['buttered_channel2'] = [butter_bandpass_filter(data, lowcut, highcut, fs, order=3) for data in df_interpolated['Raw_Value_ch2']]\n",
        "bdf['buttered_channel3'] = [butter_bandpass_filter(data, lowcut, highcut, fs, order=3) for data in df_interpolated['Raw_Value_ch3']]\n",
        "bdf['buttered_channel4'] = [butter_bandpass_filter(data, lowcut, highcut, fs, order=3) for data in df_interpolated['Raw_Value_ch4']]\n",
        "\n",
        "# print(len(buttered_channel2[1]))\n",
        "bdf"
      ],
      "metadata": {
        "id": "_8VatXArVLE4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "EMD"
      ],
      "metadata": {
        "id": "VenCXhwPlWNW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "eemd = EMD()\n",
        "imf1c1 = []\n",
        "imf1c2 = []\n",
        "imf1c3 = []\n",
        "imf1c4 = []\n",
        "\n",
        "for i in bdf['buttered_channel1']:\n",
        "    time = np.arange(0, len(i)) / fs\n",
        "    IMFs = eemd.emd(i, time)\n",
        "    i1 = IMFs[0]\n",
        "    imf1c1.append(i1)\n",
        "\n",
        "for i in bdf['buttered_channel2']:\n",
        "    time = np.arange(0, len(i)) / fs\n",
        "    IMFs = eemd.emd(i, time)\n",
        "    i1 = IMFs[0]\n",
        "    imf1c2.append(i1)\n",
        "\n",
        "for i in bdf['buttered_channel3']:\n",
        "    time = np.arange(0, len(i)) / fs\n",
        "    IMFs = eemd.emd(i, time)\n",
        "    i1 = IMFs[0]\n",
        "    imf1c3.append(i1)\n",
        "\n",
        "for i in bdf['buttered_channel4']:\n",
        "    time = np.arange(0, len(i)) / fs\n",
        "    IMFs = eemd.emd(i, time)\n",
        "    i1 = IMFs[0]\n",
        "    imf1c4.append(i1)\n",
        "\n",
        "# print(len(imf1c4[1]))\n",
        "edf = pd.DataFrame()\n",
        "edf['IMF1_channel1'] = imf1c1\n",
        "edf['IMF1_channel2'] = imf1c2\n",
        "edf['IMF1_channel3'] = imf1c3\n",
        "edf['IMF1_channel4'] = imf1c4\n",
        "edf"
      ],
      "metadata": {
        "id": "17Lr6gcCllLk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hilbert Transform"
      ],
      "metadata": {
        "id": "jZDSazuHo7BO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.signal import hilbert\n",
        "ins_phase_c1 = []\n",
        "ins_phase_c2 = []\n",
        "ins_phase_c3 = []\n",
        "ins_phase_c4 = []\n",
        "\n",
        "for i in imf1c1:\n",
        "    analytic_signal = hilbert(i)\n",
        "    instantaneous_phase = np.angle(analytic_signal)\n",
        "    ins_phase_c1.append(instantaneous_phase)\n",
        "\n",
        "for i in imf1c2:\n",
        "    analytic_signal = hilbert(i)\n",
        "    instantaneous_phase = np.angle(analytic_signal)\n",
        "    ins_phase_c2.append(instantaneous_phase)\n",
        "\n",
        "for i in imf1c3:\n",
        "    analytic_signal = hilbert(i)\n",
        "    instantaneous_phase = np.angle(analytic_signal)\n",
        "    ins_phase_c3.append(instantaneous_phase)\n",
        "\n",
        "for i in imf1c4:\n",
        "    analytic_signal = hilbert(i)\n",
        "    instantaneous_phase = np.angle(analytic_signal)\n",
        "    ins_phase_c4.append(instantaneous_phase)\n",
        "\n",
        "hdf = pd.DataFrame()\n",
        "hdf['instphase_channel1'] = ins_phase_c1\n",
        "hdf['instphase_channel2'] = ins_phase_c2\n",
        "hdf['instphase_channel3'] = ins_phase_c3\n",
        "hdf['instphase_channel4'] = ins_phase_c4\n",
        "hdf"
      ],
      "metadata": {
        "id": "M_-3JbOjnsaQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "NN Model Input Design"
      ],
      "metadata": {
        "id": "racOhHeIjv8Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mn = 5000\n",
        "for x in ins_phase_c2:\n",
        "    if len(x)<mn:\n",
        "      mn=len(x)\n",
        "print(mn)\n",
        "# max(len(ins_phase_c2))\n",
        "# max(len(hdf['instphase_channel1']))\n",
        "\n",
        "# standarizing array-size in each cell to be the same as the size of the smallest array\n",
        "minlen = (min(len(x) for x in ins_phase_c1))\n",
        "ipc1 = [lst[:minlen] for lst in ins_phase_c1 if len(lst) >= minlen]\n",
        "ipc2 = [lst[:minlen] for lst in ins_phase_c2 if len(lst) >= minlen]\n",
        "ipc3 = [lst[:minlen] for lst in ins_phase_c3 if len(lst) >= minlen]\n",
        "ipc4 = [lst[:minlen] for lst in ins_phase_c4 if len(lst) >= minlen]\n",
        "# hdf = pd.DataFrame()\n",
        "# hdf['instphase_channel1'] = ipc1\n",
        "# hdf['instphase_channel2'] = ipc2\n",
        "# hdf['instphase_channel3'] = ipc3\n",
        "# hdf['instphase_channel4'] = ipc4\n",
        "print(max(len(x) for x in hdf['instphase_channel2']))\n",
        "print(max(len(x) for x in ipc1))"
      ],
      "metadata": {
        "id": "0udAFYmoob6F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "merged_ipc = np.stack((ipc1,ipc2,ipc3,ipc4), axis=1)\n",
        "Y_train = ldf[['sys', 'dias']].to_numpy().astype('float32')\n",
        "merged_ipc = np.swapaxes(merged_ipc, 1, 2)\n",
        "merged_ipc.shape\n",
        "\n",
        "# Y_train.shape\n",
        "# merged_ipc.dtype"
      ],
      "metadata": {
        "id": "sy8Av-x4sH3b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# a = np.load('merged_ipc.npy')\n",
        "# if a.all() == merged_ipc.all():\n",
        "#   print(\"YEs\")\n",
        "import tensorflow as tf\n",
        "tf.keras.backend.clear_session()"
      ],
      "metadata": {
        "id": "YHA3-I46PDgL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train = merged_ipc\n",
        "Y_train = ldf[['dias']].to_numpy().astype('float32')\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X_train, Y_train, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "L1DsjBv8OK1x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv1D, MaxPooling1D, GlobalAveragePooling1D, Flatten, Dense, BatchNormalization\n",
        "tf.keras.backend.clear_session()\n",
        "\n",
        "input_shape =  (88, 4)\n",
        "model = Sequential()\n",
        "\n",
        "#first Conv layer\n",
        "model.add(Conv1D(filters=100, kernel_size=21, strides=1, input_shape=input_shape))\n",
        "model.add(BatchNormalization())\n",
        "model.add(tf.keras.layers.ReLU())\n",
        "model.add(MaxPooling1D(pool_size=2))\n",
        "\n",
        "#second Conv layer\n",
        "model.add(Conv1D(filters=200, kernel_size=5))\n",
        "model.add(BatchNormalization())\n",
        "model.add(tf.keras.layers.ReLU())\n",
        "model.add(MaxPooling1D(pool_size=2))\n",
        "\n",
        "#third Conv layer\n",
        "model.add(Conv1D(filters=300, kernel_size=5))\n",
        "model.add(BatchNormalization())\n",
        "model.add(tf.keras.layers.ReLU())\n",
        "model.add(MaxPooling1D(pool_size=2))\n",
        "\n",
        "#GlobalAveragePooling1D layer\n",
        "model.add(GlobalAveragePooling1D())\n",
        "#Final dense layer\n",
        "model.add(Dense(1, activation='linear'))\n",
        "\n",
        "model.compile(loss=tf.keras.losses.mean_squared_error, optimizer=tf.keras.optimizers.Adam(learning_rate=0.001))\n",
        "model.summary()\n",
        "history = model.fit(X_train, Y_train, epochs=50, validation_data=(X_test, Y_test), batch_size=64)"
      ],
      "metadata": {
        "id": "OMvUV4TIJ5Xe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = model.predict(X_test)\n",
        "Y_pred = []\n",
        "for i in range(len(X_test)):\n",
        "  Y_pred.append(predictions[i])\n",
        "yf = pd.DataFrame(Y_pred, columns=['predicted'])\n",
        "yf['test-set'] = Y_test\n",
        "yf.head(40)"
      ],
      "metadata": {
        "id": "eIp1Ldw7Ongj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "# Plotting training and validation loss\n",
        "plt.figure(figsize=(10, 6))\n",
        "\n",
        "# Training loss\n",
        "plt.plot(history.history['loss'], label='Training Loss', marker='o')\n",
        "\n",
        "# Validation loss\n",
        "plt.plot(history.history['val_loss'], label='Validation Loss', marker='o')\n",
        "\n",
        "# Adding labels and title\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Training Performance(dias) for input shape (1650,88,4)')\n",
        "plt.legend()\n",
        "\n",
        "# Adding grid for better readability\n",
        "plt.grid(True)\n",
        "\n",
        "# Show plot\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "MTZ4OvK9lovA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xSt4peOcnJLu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = model.predict(X_test)\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "\n",
        "# Plotting predictions against ground truth\n",
        "plt.scatter(Y_test, predictions)\n",
        "plt.xlabel('True Values')\n",
        "plt.ylabel('Predictions')\n",
        "plt.title('Model Predictions vs. Ground Truth')\n",
        "\n",
        "# Show plot\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "v0evohtPZwSd"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}